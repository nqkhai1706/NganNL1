{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNz1LWp5R6K+rvJ689LSNfN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nqkhai1706/NganNL1/blob/main/test_lenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjAJybVU9d9c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# ========================duong dan======================================\n",
        "\n",
        "# path=\"./vtho/\"\n",
        "# categories = ['BD_KT','DT_mu','vtho_1']\n",
        "\n",
        "# path=\"./tay/\"\n",
        "# categories = ['BD_KT','DT_mu', 'tay_1', 'tay_2','tay_3']\n",
        "\n",
        "# path=\"./chan/\"\n",
        "# categories = ['BD_KT', 'chan_1', 'chan_2','DT_mu']\n",
        "\n",
        "path=\"./luon/\"\n",
        "categories = ['BD_KT','DT_mu', 'luon_1', 'luon_2','luon_3']\n",
        "\n",
        "# path=\"./bung/\"\n",
        "# categories = ['BD_KT', 'bung_1', 'bung_2','bung_3','DT_mu']\n",
        "\n",
        "# path=\"./toanthan/\"\n",
        "# categories = ['BD_KT','DT_mu','toanthan_1', 'toanthan_2','toanthan_3']\n",
        "\n",
        "# path=\"./nhay/\"\n",
        "# categories = ['BD_KT','DT_mu', 'nhay_1', 'nhay_2']\n",
        "\n",
        "# path=\"./dieuhoa/\"\n",
        "# categories = ['BD_KT', 'dieuhoa_1', 'dieuhoa_2','DT_mu']\n",
        "\n",
        "# =============================resize kich thuoc anh=================================\n",
        "\n",
        "data = []#dữ liệu\n",
        "labels = []#nhãn\n",
        "imagePaths = []\n",
        "HEIGHT = 64\n",
        "WIDTH = 64\n",
        "# 24 24\n",
        "N_CHANNELS = 3\n",
        "\n",
        "# ===========================lay ngau nhien anh===================================\n",
        "\n",
        "for k, category in enumerate(categories):\n",
        "    for f in os.listdir(path+category):\n",
        "        imagePaths.append([path+category+'/'+f, k])\n",
        "\n",
        "import random\n",
        "random.shuffle(imagePaths)\n",
        "# print(imagePaths[:10])\n",
        "\n",
        "# =======================tien xu ly=======================================\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "    image = cv2.imread(imagePath[0])\n",
        "    image = cv2.resize(image, (WIDTH, HEIGHT))  # .flatten()\n",
        "    data.append(image)\n",
        "    label = imagePath[1]\n",
        "    labels.append(label)\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "labels = np.array(labels)\n",
        "\n",
        "plt.subplots(3,4)\n",
        "for i in range(12):\n",
        "    plt.subplot(3,4, i+1)\n",
        "    plt.imshow(data[i])\n",
        "    plt.axis('off')\n",
        "    plt.title(categories[labels[i]])\n",
        "# plt.show()\n",
        "\n",
        "# ============================chia tap dl==================================\n",
        "\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42)# random_state=30)\n",
        "\n",
        "trainY = np_utils.to_categorical(trainY, len(categories))\n",
        "\n",
        "# ===========================huan luyen===================================\n",
        "\n",
        "EPOCHS = 10\n",
        "INIT_LR = 1e-3\n",
        "BS =100\n",
        "\n",
        "class_names = categories\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(WIDTH, HEIGHT, 3)))\n",
        "model.add(MaxPooling2D(strides=2))\n",
        "model.add(Convolution2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
        "model.add(MaxPooling2D(strides=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(84, activation='relu'))\n",
        "model.add(Dense(len(class_names), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(trainX, trainY, batch_size=BS, epochs=EPOCHS, verbose=1)\n",
        "\n",
        "# model.save(\"vuontho100.h5\")\n",
        "# ==========================kiem tra su dung cua mo hinh====================================\n",
        "\n",
        "from numpy import argmax\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "pred = model.predict(testX)\n",
        "predictions = argmax(pred, axis=1) # return to label\n",
        "\n",
        "cm = confusion_matrix(testY, predictions)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "plt.title('Model confusion matrix')\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + categories)\n",
        "ax.set_yticklabels([''] + categories)\n",
        "\n",
        "for i in range(len(class_names)):\n",
        "    for j in range(len(class_names)):\n",
        "        ax.text(i, j, cm[j, i], va='center', ha='center')\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(testY, predictions)\n",
        "print(\"Accuracy : %.2f%%\" % (accuracy*100.0))\n",
        "print(\"\\n\")\n",
        "# ----------------------------------------------\n",
        "\n",
        "recall= recall_score(testY, predictions,average='weighted')\n",
        "print(\"Recall :%.2f%%\" % (recall*100))\n",
        "print(\"\\n\")\n",
        "# ----------------------------------------------\n",
        "\n",
        "precision = precision_score(testY, predictions,average='weighted')\n",
        "print(\"Precision : %.2f%%\" % (precision*100.0))\n",
        "print(\"\\n\")\n",
        "# ----------------------------------------------\n",
        "\n",
        "f1 = f1_score(testY, predictions,average='weighted')\n",
        "print(\"F1 : %.2f%%\" % (f1*100.0))\n",
        "print(\"\\n\")\n",
        "\n",
        "# ==============================dua anh vao kiem tra================================\n",
        "\n",
        "# from numpy import argmax\n",
        "# import PIL\n",
        "# import matplotlib.pyplot as plt\n",
        "# from tensorflow.keras.preprocessing import image\n",
        "# img_path=\"./nhan480.jpg\"\n",
        "\n",
        "# img=image.load_img(img_path,target_size=(32,32))\n",
        "# img_array=image.img_to_array(img)\n",
        "# from tensorflow.keras.applications.resnet50 import preprocess_input,decode_predictions\n",
        "# img_batch=np.expand_dims(img_array, axis=0)\n",
        "# img_preprocessed=preprocess_input(img_batch)\n",
        "\n",
        "# pred=model.predict(img_preprocessed)\n",
        "# Res=argmax(pred,axis=1)\n",
        "# print(pred)\n",
        "\n",
        "# plt.imshow(img)\n",
        "# plt.show()\n",
        "# print(categories[Res[0]],pred[0][Res[0]]*100)\n",
        "\n",
        "\n"
      ]
    }
  ]
}